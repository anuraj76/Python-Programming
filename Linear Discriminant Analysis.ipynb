{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import standardize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_extraction import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = standardize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_discriminants=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlxtend.feature_extraction.linear_discriminant_analysis.LinearDiscriminantAnalysis at 0x11651ec8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lda = lda.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.78399213+0.j, -0.02138789+0.j],\n",
       "       [-1.56599117+0.j, -0.39039612+0.j],\n",
       "       [-1.65167828+0.j, -0.21283157+0.j],\n",
       "       [-1.49902607+0.j, -0.34511877+0.j],\n",
       "       [-1.80228426+0.j,  0.05273823+0.j],\n",
       "       [-1.71663551+0.j,  0.39464792+0.j],\n",
       "       [-1.59735842+0.j,  0.01042189+0.j],\n",
       "       [-1.68044277+0.j, -0.12436278+0.j],\n",
       "       [-1.43923591+0.j, -0.46313164+0.j],\n",
       "       [-1.61313608+0.j, -0.45035938+0.j],\n",
       "       [-1.86185948+0.j,  0.09639322+0.j],\n",
       "       [-1.59518554+0.j, -0.15321155+0.j],\n",
       "       [-1.60779243+0.j, -0.49470966+0.j],\n",
       "       [-1.66471505+0.j, -0.40561391+0.j],\n",
       "       [-2.19058476+0.j,  0.40508613+0.j],\n",
       "       [-2.05091937+0.j,  0.822049  +0.j],\n",
       "       [-1.91304693+0.j,  0.51189714+0.j],\n",
       "       [-1.72411369+0.j,  0.08315742+0.j],\n",
       "       [-1.79437621+0.j,  0.21551296+0.j],\n",
       "       [-1.78411878+0.j,  0.27552817+0.j],\n",
       "       [-1.65454582+0.j, -0.18391446+0.j],\n",
       "       [-1.68787102+0.j,  0.30617912+0.j],\n",
       "       [-1.92638692+0.j,  0.17091452+0.j],\n",
       "       [-1.3843096 +0.j,  0.0565224 +0.j],\n",
       "       [-1.44787697+0.j, -0.24114847+0.j],\n",
       "       [-1.48586265+0.j, -0.4492525 +0.j],\n",
       "       [-1.51158303+0.j,  0.05541552+0.j],\n",
       "       [-1.75296647+0.j, -0.05093196+0.j],\n",
       "       [-1.76570001+0.j, -0.095514  +0.j],\n",
       "       [-1.50436972+0.j, -0.30076849+0.j],\n",
       "       [-1.48607759+0.j, -0.37489461+0.j],\n",
       "       [-1.63299464+0.j,  0.08380076+0.j],\n",
       "       [-2.03106081+0.j,  0.28788886+0.j],\n",
       "       [-2.11088611+0.j,  0.49494552+0.j],\n",
       "       [-1.61313608+0.j, -0.45035938+0.j],\n",
       "       [-1.75501271+0.j, -0.18421457+0.j],\n",
       "       [-1.90540375+0.j,  0.00699736+0.j],\n",
       "       [-1.61313608+0.j, -0.45035938+0.j],\n",
       "       [-1.52470808+0.j, -0.35992498+0.j],\n",
       "       [-1.69851996+0.j, -0.12459455+0.j],\n",
       "       [-1.75513935+0.j,  0.11270149+0.j],\n",
       "       [-1.22832161+0.j, -0.77287192+0.j],\n",
       "       [-1.59744671+0.j, -0.21213628+0.j],\n",
       "       [-1.42819545+0.j,  0.33840048+0.j],\n",
       "       [-1.52782891+0.j,  0.26282425+0.j],\n",
       "       [-1.48803554+0.j, -0.28561905+0.j],\n",
       "       [-1.79489437+0.j,  0.14167056+0.j],\n",
       "       [-1.58449824+0.j, -0.24191212+0.j],\n",
       "       [-1.84378229+0.j,  0.09662498+0.j],\n",
       "       [-1.69317631+0.j, -0.16894483+0.j],\n",
       "       [ 0.32058479+0.j,  0.03976303+0.j],\n",
       "       [ 0.39072066+0.j,  0.20432354+0.j],\n",
       "       [ 0.53311545+0.j,  0.01202113+0.j],\n",
       "       [ 0.51546804+0.j, -0.52116882+0.j],\n",
       "       [ 0.56722359+0.j, -0.12079794+0.j],\n",
       "       [ 0.54298136+0.j, -0.29872212+0.j],\n",
       "       [ 0.53051269+0.j,  0.32437035+0.j],\n",
       "       [ 0.06420654+0.j, -0.55433363+0.j],\n",
       "       [ 0.39302019+0.j, -0.25622596+0.j],\n",
       "       [ 0.43499794+0.j, -0.0910385 +0.j],\n",
       "       [ 0.28981233+0.j, -0.90876743+0.j],\n",
       "       [ 0.40653668+0.j,  0.14563058+0.j],\n",
       "       [ 0.28181607+0.j, -0.90985791+0.j],\n",
       "       [ 0.59238744+0.j, -0.17983414+0.j],\n",
       "       [ 0.08276354+0.j,  0.03921476+0.j],\n",
       "       [ 0.2638771 +0.j,  0.05450089+0.j],\n",
       "       [ 0.60807681+0.j,  0.05838896+0.j],\n",
       "       [ 0.18522673+0.j, -0.56923492+0.j],\n",
       "       [ 0.7905682 +0.j, -0.53415646+0.j],\n",
       "       [ 0.25579248+0.j, -0.55339018+0.j],\n",
       "       [ 0.80805051+0.j,  0.43118136+0.j],\n",
       "       [ 0.22515832+0.j, -0.15308765+0.j],\n",
       "       [ 0.85979448+0.j, -0.42995439+0.j],\n",
       "       [ 0.50899987+0.j, -0.4628191 +0.j],\n",
       "       [ 0.28186601+0.j, -0.16782551+0.j],\n",
       "       [ 0.31832361+0.j, -0.0191617 +0.j],\n",
       "       [ 0.55131928+0.j, -0.28466316+0.j],\n",
       "       [ 0.77449889+0.j,  0.11836861+0.j],\n",
       "       [ 0.57213737+0.j, -0.01643246+0.j],\n",
       "       [-0.0549439 +0.j, -0.46702367+0.j],\n",
       "       [ 0.26113613+0.j, -0.59774046+0.j],\n",
       "       [ 0.15215482+0.j, -0.67297346+0.j],\n",
       "       [ 0.20677791+0.j, -0.3015197 +0.j],\n",
       "       [ 0.99937158+0.j, -0.2355497 +0.j],\n",
       "       [ 0.64423119+0.j,  0.05885249+0.j],\n",
       "       [ 0.45016923+0.j,  0.45758461+0.j],\n",
       "       [ 0.47106412+0.j,  0.07110928+0.j],\n",
       "       [ 0.56726195+0.j, -0.64027217+0.j],\n",
       "       [ 0.2919085 +0.j, -0.03345242+0.j],\n",
       "       [ 0.44272941+0.j, -0.37338011+0.j],\n",
       "       [ 0.54289307+0.j, -0.52128029+0.j],\n",
       "       [ 0.50691527+0.j, -0.07662748+0.j],\n",
       "       [ 0.29225008+0.j, -0.40472636+0.j],\n",
       "       [ 0.08249867+0.j, -0.62845975+0.j],\n",
       "       [ 0.4501193 +0.j, -0.28444778+0.j],\n",
       "       [ 0.26305572+0.j, -0.16754179+0.j],\n",
       "       [ 0.35930348+0.j, -0.13689084+0.j],\n",
       "       [ 0.31802039+0.j, -0.16736198+0.j],\n",
       "       [-0.09574727+0.j, -0.28842059+0.j],\n",
       "       [ 0.34656994+0.j, -0.18147289+0.j],\n",
       "       [ 1.70775582+0.j,  0.8842181 +0.j],\n",
       "       [ 1.2151613 +0.j,  0.07854975+0.j],\n",
       "       [ 1.38362961+0.j,  0.271812  +0.j],\n",
       "       [ 1.23767255+0.j, -0.02592721+0.j],\n",
       "       [ 1.50286834+0.j,  0.40706021+0.j],\n",
       "       [ 1.63696365+0.j,  0.06546703+0.j],\n",
       "       [ 1.03622061+0.j, -0.10036983+0.j],\n",
       "       [ 1.40062064+0.j, -0.23343102+0.j],\n",
       "       [ 1.40904676+0.j, -0.3810563 +0.j],\n",
       "       [ 1.48505602+0.j,  1.07450296+0.j],\n",
       "       [ 0.96665283+0.j,  0.55094445+0.j],\n",
       "       [ 1.20490387+0.j,  0.01853454+0.j],\n",
       "       [ 1.24144976+0.j,  0.38975653+0.j],\n",
       "       [ 1.31675271+0.j,  0.06485042+0.j],\n",
       "       [ 1.47818421+0.j,  0.67517062+0.j],\n",
       "       [ 1.26257107+0.j,  0.80618752+0.j],\n",
       "       [ 1.11604599+0.j,  0.07681591+0.j],\n",
       "       [ 1.43691324+0.j,  0.73162308+0.j],\n",
       "       [ 2.03142918+0.j, -0.10918847+0.j],\n",
       "       [ 1.07223686+0.j, -0.68025446+0.j],\n",
       "       [ 1.36859654+0.j,  0.68777946+0.j],\n",
       "       [ 1.1766191 +0.j,  0.31607755+0.j],\n",
       "       [ 1.6808495 +0.j, -0.21641106+0.j],\n",
       "       [ 0.96669119+0.j,  0.03147023+0.j],\n",
       "       [ 1.24862472+0.j,  0.55304674+0.j],\n",
       "       [ 1.16228131+0.j,  0.07642072+0.j],\n",
       "       [ 0.89929621+0.j,  0.13490865+0.j],\n",
       "       [ 0.89373762+0.j,  0.25361682+0.j],\n",
       "       [ 1.43560001+0.j,  0.21358258+0.j],\n",
       "       [ 1.01705734+0.j, -0.22183398+0.j],\n",
       "       [ 1.3805855 +0.j, -0.14438722+0.j],\n",
       "       [ 1.1336934 +0.j,  0.61000586+0.j],\n",
       "       [ 1.49547846+0.j,  0.31812788+0.j],\n",
       "       [ 0.84889225+0.j, -0.26689595+0.j],\n",
       "       [ 1.14342109+0.j, -0.66532796+0.j],\n",
       "       [ 1.49312908+0.j,  0.4208874 +0.j],\n",
       "       [ 1.41509664+0.j,  0.97081637+0.j],\n",
       "       [ 1.09775387+0.j,  0.15094203+0.j],\n",
       "       [ 0.86271196+0.j,  0.28316089+0.j],\n",
       "       [ 1.1379004 +0.j,  0.49273142+0.j],\n",
       "       [ 1.45189583+0.j,  0.74820625+0.j],\n",
       "       [ 1.11034872+0.j,  0.78975895+0.j],\n",
       "       [ 1.2151613 +0.j,  0.07854975+0.j],\n",
       "       [ 1.48487944+0.j,  0.62938661+0.j],\n",
       "       [ 1.4881385 +0.j,  0.97122795+0.j],\n",
       "       [ 1.23197528+0.j,  0.68701582+0.j],\n",
       "       [ 1.14841112+0.j, -0.04108548+0.j],\n",
       "       [ 1.08849432+0.j,  0.37384344+0.j],\n",
       "       [ 1.27508967+0.j,  0.92512745+0.j],\n",
       "       [ 1.02809771+0.j,  0.19545574+0.j]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asm1318\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Complex data not supported\n[[-1.78399213+0.j -0.02138789+0.j]\n [-1.56599117+0.j -0.39039612+0.j]\n [-1.65167828+0.j -0.21283157+0.j]\n [-1.49902607+0.j -0.34511877+0.j]\n [-1.80228426+0.j  0.05273823+0.j]\n [-1.71663551+0.j  0.39464792+0.j]\n [-1.59735842+0.j  0.01042189+0.j]\n [-1.68044277+0.j -0.12436278+0.j]\n [-1.43923591+0.j -0.46313164+0.j]\n [-1.61313608+0.j -0.45035938+0.j]\n [-1.86185948+0.j  0.09639322+0.j]\n [-1.59518554+0.j -0.15321155+0.j]\n [-1.60779243+0.j -0.49470966+0.j]\n [-1.66471505+0.j -0.40561391+0.j]\n [-2.19058476+0.j  0.40508613+0.j]\n [-2.05091937+0.j  0.822049  +0.j]\n [-1.91304693+0.j  0.51189714+0.j]\n [-1.72411369+0.j  0.08315742+0.j]\n [-1.79437621+0.j  0.21551296+0.j]\n [-1.78411878+0.j  0.27552817+0.j]\n [-1.65454582+0.j -0.18391446+0.j]\n [-1.68787102+0.j  0.30617912+0.j]\n [-1.92638692+0.j  0.17091452+0.j]\n [-1.3843096 +0.j  0.0565224 +0.j]\n [-1.44787697+0.j -0.24114847+0.j]\n [-1.48586265+0.j -0.4492525 +0.j]\n [-1.51158303+0.j  0.05541552+0.j]\n [-1.75296647+0.j -0.05093196+0.j]\n [-1.76570001+0.j -0.095514  +0.j]\n [-1.50436972+0.j -0.30076849+0.j]\n [-1.48607759+0.j -0.37489461+0.j]\n [-1.63299464+0.j  0.08380076+0.j]\n [-2.03106081+0.j  0.28788886+0.j]\n [-2.11088611+0.j  0.49494552+0.j]\n [-1.61313608+0.j -0.45035938+0.j]\n [-1.75501271+0.j -0.18421457+0.j]\n [-1.90540375+0.j  0.00699736+0.j]\n [-1.61313608+0.j -0.45035938+0.j]\n [-1.52470808+0.j -0.35992498+0.j]\n [-1.69851996+0.j -0.12459455+0.j]\n [-1.75513935+0.j  0.11270149+0.j]\n [-1.22832161+0.j -0.77287192+0.j]\n [-1.59744671+0.j -0.21213628+0.j]\n [-1.42819545+0.j  0.33840048+0.j]\n [-1.52782891+0.j  0.26282425+0.j]\n [-1.48803554+0.j -0.28561905+0.j]\n [-1.79489437+0.j  0.14167056+0.j]\n [-1.58449824+0.j -0.24191212+0.j]\n [-1.84378229+0.j  0.09662498+0.j]\n [-1.69317631+0.j -0.16894483+0.j]\n [ 0.32058479+0.j  0.03976303+0.j]\n [ 0.39072066+0.j  0.20432354+0.j]\n [ 0.53311545+0.j  0.01202113+0.j]\n [ 0.51546804+0.j -0.52116882+0.j]\n [ 0.56722359+0.j -0.12079794+0.j]\n [ 0.54298136+0.j -0.29872212+0.j]\n [ 0.53051269+0.j  0.32437035+0.j]\n [ 0.06420654+0.j -0.55433363+0.j]\n [ 0.39302019+0.j -0.25622596+0.j]\n [ 0.43499794+0.j -0.0910385 +0.j]\n [ 0.28981233+0.j -0.90876743+0.j]\n [ 0.40653668+0.j  0.14563058+0.j]\n [ 0.28181607+0.j -0.90985791+0.j]\n [ 0.59238744+0.j -0.17983414+0.j]\n [ 0.08276354+0.j  0.03921476+0.j]\n [ 0.2638771 +0.j  0.05450089+0.j]\n [ 0.60807681+0.j  0.05838896+0.j]\n [ 0.18522673+0.j -0.56923492+0.j]\n [ 0.7905682 +0.j -0.53415646+0.j]\n [ 0.25579248+0.j -0.55339018+0.j]\n [ 0.80805051+0.j  0.43118136+0.j]\n [ 0.22515832+0.j -0.15308765+0.j]\n [ 0.85979448+0.j -0.42995439+0.j]\n [ 0.50899987+0.j -0.4628191 +0.j]\n [ 0.28186601+0.j -0.16782551+0.j]\n [ 0.31832361+0.j -0.0191617 +0.j]\n [ 0.55131928+0.j -0.28466316+0.j]\n [ 0.77449889+0.j  0.11836861+0.j]\n [ 0.57213737+0.j -0.01643246+0.j]\n [-0.0549439 +0.j -0.46702367+0.j]\n [ 0.26113613+0.j -0.59774046+0.j]\n [ 0.15215482+0.j -0.67297346+0.j]\n [ 0.20677791+0.j -0.3015197 +0.j]\n [ 0.99937158+0.j -0.2355497 +0.j]\n [ 0.64423119+0.j  0.05885249+0.j]\n [ 0.45016923+0.j  0.45758461+0.j]\n [ 0.47106412+0.j  0.07110928+0.j]\n [ 0.56726195+0.j -0.64027217+0.j]\n [ 0.2919085 +0.j -0.03345242+0.j]\n [ 0.44272941+0.j -0.37338011+0.j]\n [ 0.54289307+0.j -0.52128029+0.j]\n [ 0.50691527+0.j -0.07662748+0.j]\n [ 0.29225008+0.j -0.40472636+0.j]\n [ 0.08249867+0.j -0.62845975+0.j]\n [ 0.4501193 +0.j -0.28444778+0.j]\n [ 0.26305572+0.j -0.16754179+0.j]\n [ 0.35930348+0.j -0.13689084+0.j]\n [ 0.31802039+0.j -0.16736198+0.j]\n [-0.09574727+0.j -0.28842059+0.j]\n [ 0.34656994+0.j -0.18147289+0.j]\n [ 1.70775582+0.j  0.8842181 +0.j]\n [ 1.2151613 +0.j  0.07854975+0.j]\n [ 1.38362961+0.j  0.271812  +0.j]\n [ 1.23767255+0.j -0.02592721+0.j]\n [ 1.50286834+0.j  0.40706021+0.j]\n [ 1.63696365+0.j  0.06546703+0.j]\n [ 1.03622061+0.j -0.10036983+0.j]\n [ 1.40062064+0.j -0.23343102+0.j]\n [ 1.40904676+0.j -0.3810563 +0.j]\n [ 1.48505602+0.j  1.07450296+0.j]\n [ 0.96665283+0.j  0.55094445+0.j]\n [ 1.20490387+0.j  0.01853454+0.j]\n [ 1.24144976+0.j  0.38975653+0.j]\n [ 1.31675271+0.j  0.06485042+0.j]\n [ 1.47818421+0.j  0.67517062+0.j]\n [ 1.26257107+0.j  0.80618752+0.j]\n [ 1.11604599+0.j  0.07681591+0.j]\n [ 1.43691324+0.j  0.73162308+0.j]\n [ 2.03142918+0.j -0.10918847+0.j]\n [ 1.07223686+0.j -0.68025446+0.j]\n [ 1.36859654+0.j  0.68777946+0.j]\n [ 1.1766191 +0.j  0.31607755+0.j]\n [ 1.6808495 +0.j -0.21641106+0.j]\n [ 0.96669119+0.j  0.03147023+0.j]\n [ 1.24862472+0.j  0.55304674+0.j]\n [ 1.16228131+0.j  0.07642072+0.j]\n [ 0.89929621+0.j  0.13490865+0.j]\n [ 0.89373762+0.j  0.25361682+0.j]\n [ 1.43560001+0.j  0.21358258+0.j]\n [ 1.01705734+0.j -0.22183398+0.j]\n [ 1.3805855 +0.j -0.14438722+0.j]\n [ 1.1336934 +0.j  0.61000586+0.j]\n [ 1.49547846+0.j  0.31812788+0.j]\n [ 0.84889225+0.j -0.26689595+0.j]\n [ 1.14342109+0.j -0.66532796+0.j]\n [ 1.49312908+0.j  0.4208874 +0.j]\n [ 1.41509664+0.j  0.97081637+0.j]\n [ 1.09775387+0.j  0.15094203+0.j]\n [ 0.86271196+0.j  0.28316089+0.j]\n [ 1.1379004 +0.j  0.49273142+0.j]\n [ 1.45189583+0.j  0.74820625+0.j]\n [ 1.11034872+0.j  0.78975895+0.j]\n [ 1.2151613 +0.j  0.07854975+0.j]\n [ 1.48487944+0.j  0.62938661+0.j]\n [ 1.4881385 +0.j  0.97122795+0.j]\n [ 1.23197528+0.j  0.68701582+0.j]\n [ 1.14841112+0.j -0.04108548+0.j]\n [ 1.08849432+0.j  0.37384344+0.j]\n [ 1.27508967+0.j  0.92512745+0.j]\n [ 1.02809771+0.j  0.19545574+0.j]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mComplexWarning\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mComplexWarning\u001b[0m: Casting complex values to real discards the imaginary part",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2ef4ac972249>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_lda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1532\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1533\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n\u001b[1;32m--> 499\u001b[1;33m                                  \"{}\\n\".format(array))\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;31m# It is possible that the np.array(..) gave no warning. This happens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Complex data not supported\n[[-1.78399213+0.j -0.02138789+0.j]\n [-1.56599117+0.j -0.39039612+0.j]\n [-1.65167828+0.j -0.21283157+0.j]\n [-1.49902607+0.j -0.34511877+0.j]\n [-1.80228426+0.j  0.05273823+0.j]\n [-1.71663551+0.j  0.39464792+0.j]\n [-1.59735842+0.j  0.01042189+0.j]\n [-1.68044277+0.j -0.12436278+0.j]\n [-1.43923591+0.j -0.46313164+0.j]\n [-1.61313608+0.j -0.45035938+0.j]\n [-1.86185948+0.j  0.09639322+0.j]\n [-1.59518554+0.j -0.15321155+0.j]\n [-1.60779243+0.j -0.49470966+0.j]\n [-1.66471505+0.j -0.40561391+0.j]\n [-2.19058476+0.j  0.40508613+0.j]\n [-2.05091937+0.j  0.822049  +0.j]\n [-1.91304693+0.j  0.51189714+0.j]\n [-1.72411369+0.j  0.08315742+0.j]\n [-1.79437621+0.j  0.21551296+0.j]\n [-1.78411878+0.j  0.27552817+0.j]\n [-1.65454582+0.j -0.18391446+0.j]\n [-1.68787102+0.j  0.30617912+0.j]\n [-1.92638692+0.j  0.17091452+0.j]\n [-1.3843096 +0.j  0.0565224 +0.j]\n [-1.44787697+0.j -0.24114847+0.j]\n [-1.48586265+0.j -0.4492525 +0.j]\n [-1.51158303+0.j  0.05541552+0.j]\n [-1.75296647+0.j -0.05093196+0.j]\n [-1.76570001+0.j -0.095514  +0.j]\n [-1.50436972+0.j -0.30076849+0.j]\n [-1.48607759+0.j -0.37489461+0.j]\n [-1.63299464+0.j  0.08380076+0.j]\n [-2.03106081+0.j  0.28788886+0.j]\n [-2.11088611+0.j  0.49494552+0.j]\n [-1.61313608+0.j -0.45035938+0.j]\n [-1.75501271+0.j -0.18421457+0.j]\n [-1.90540375+0.j  0.00699736+0.j]\n [-1.61313608+0.j -0.45035938+0.j]\n [-1.52470808+0.j -0.35992498+0.j]\n [-1.69851996+0.j -0.12459455+0.j]\n [-1.75513935+0.j  0.11270149+0.j]\n [-1.22832161+0.j -0.77287192+0.j]\n [-1.59744671+0.j -0.21213628+0.j]\n [-1.42819545+0.j  0.33840048+0.j]\n [-1.52782891+0.j  0.26282425+0.j]\n [-1.48803554+0.j -0.28561905+0.j]\n [-1.79489437+0.j  0.14167056+0.j]\n [-1.58449824+0.j -0.24191212+0.j]\n [-1.84378229+0.j  0.09662498+0.j]\n [-1.69317631+0.j -0.16894483+0.j]\n [ 0.32058479+0.j  0.03976303+0.j]\n [ 0.39072066+0.j  0.20432354+0.j]\n [ 0.53311545+0.j  0.01202113+0.j]\n [ 0.51546804+0.j -0.52116882+0.j]\n [ 0.56722359+0.j -0.12079794+0.j]\n [ 0.54298136+0.j -0.29872212+0.j]\n [ 0.53051269+0.j  0.32437035+0.j]\n [ 0.06420654+0.j -0.55433363+0.j]\n [ 0.39302019+0.j -0.25622596+0.j]\n [ 0.43499794+0.j -0.0910385 +0.j]\n [ 0.28981233+0.j -0.90876743+0.j]\n [ 0.40653668+0.j  0.14563058+0.j]\n [ 0.28181607+0.j -0.90985791+0.j]\n [ 0.59238744+0.j -0.17983414+0.j]\n [ 0.08276354+0.j  0.03921476+0.j]\n [ 0.2638771 +0.j  0.05450089+0.j]\n [ 0.60807681+0.j  0.05838896+0.j]\n [ 0.18522673+0.j -0.56923492+0.j]\n [ 0.7905682 +0.j -0.53415646+0.j]\n [ 0.25579248+0.j -0.55339018+0.j]\n [ 0.80805051+0.j  0.43118136+0.j]\n [ 0.22515832+0.j -0.15308765+0.j]\n [ 0.85979448+0.j -0.42995439+0.j]\n [ 0.50899987+0.j -0.4628191 +0.j]\n [ 0.28186601+0.j -0.16782551+0.j]\n [ 0.31832361+0.j -0.0191617 +0.j]\n [ 0.55131928+0.j -0.28466316+0.j]\n [ 0.77449889+0.j  0.11836861+0.j]\n [ 0.57213737+0.j -0.01643246+0.j]\n [-0.0549439 +0.j -0.46702367+0.j]\n [ 0.26113613+0.j -0.59774046+0.j]\n [ 0.15215482+0.j -0.67297346+0.j]\n [ 0.20677791+0.j -0.3015197 +0.j]\n [ 0.99937158+0.j -0.2355497 +0.j]\n [ 0.64423119+0.j  0.05885249+0.j]\n [ 0.45016923+0.j  0.45758461+0.j]\n [ 0.47106412+0.j  0.07110928+0.j]\n [ 0.56726195+0.j -0.64027217+0.j]\n [ 0.2919085 +0.j -0.03345242+0.j]\n [ 0.44272941+0.j -0.37338011+0.j]\n [ 0.54289307+0.j -0.52128029+0.j]\n [ 0.50691527+0.j -0.07662748+0.j]\n [ 0.29225008+0.j -0.40472636+0.j]\n [ 0.08249867+0.j -0.62845975+0.j]\n [ 0.4501193 +0.j -0.28444778+0.j]\n [ 0.26305572+0.j -0.16754179+0.j]\n [ 0.35930348+0.j -0.13689084+0.j]\n [ 0.31802039+0.j -0.16736198+0.j]\n [-0.09574727+0.j -0.28842059+0.j]\n [ 0.34656994+0.j -0.18147289+0.j]\n [ 1.70775582+0.j  0.8842181 +0.j]\n [ 1.2151613 +0.j  0.07854975+0.j]\n [ 1.38362961+0.j  0.271812  +0.j]\n [ 1.23767255+0.j -0.02592721+0.j]\n [ 1.50286834+0.j  0.40706021+0.j]\n [ 1.63696365+0.j  0.06546703+0.j]\n [ 1.03622061+0.j -0.10036983+0.j]\n [ 1.40062064+0.j -0.23343102+0.j]\n [ 1.40904676+0.j -0.3810563 +0.j]\n [ 1.48505602+0.j  1.07450296+0.j]\n [ 0.96665283+0.j  0.55094445+0.j]\n [ 1.20490387+0.j  0.01853454+0.j]\n [ 1.24144976+0.j  0.38975653+0.j]\n [ 1.31675271+0.j  0.06485042+0.j]\n [ 1.47818421+0.j  0.67517062+0.j]\n [ 1.26257107+0.j  0.80618752+0.j]\n [ 1.11604599+0.j  0.07681591+0.j]\n [ 1.43691324+0.j  0.73162308+0.j]\n [ 2.03142918+0.j -0.10918847+0.j]\n [ 1.07223686+0.j -0.68025446+0.j]\n [ 1.36859654+0.j  0.68777946+0.j]\n [ 1.1766191 +0.j  0.31607755+0.j]\n [ 1.6808495 +0.j -0.21641106+0.j]\n [ 0.96669119+0.j  0.03147023+0.j]\n [ 1.24862472+0.j  0.55304674+0.j]\n [ 1.16228131+0.j  0.07642072+0.j]\n [ 0.89929621+0.j  0.13490865+0.j]\n [ 0.89373762+0.j  0.25361682+0.j]\n [ 1.43560001+0.j  0.21358258+0.j]\n [ 1.01705734+0.j -0.22183398+0.j]\n [ 1.3805855 +0.j -0.14438722+0.j]\n [ 1.1336934 +0.j  0.61000586+0.j]\n [ 1.49547846+0.j  0.31812788+0.j]\n [ 0.84889225+0.j -0.26689595+0.j]\n [ 1.14342109+0.j -0.66532796+0.j]\n [ 1.49312908+0.j  0.4208874 +0.j]\n [ 1.41509664+0.j  0.97081637+0.j]\n [ 1.09775387+0.j  0.15094203+0.j]\n [ 0.86271196+0.j  0.28316089+0.j]\n [ 1.1379004 +0.j  0.49273142+0.j]\n [ 1.45189583+0.j  0.74820625+0.j]\n [ 1.11034872+0.j  0.78975895+0.j]\n [ 1.2151613 +0.j  0.07854975+0.j]\n [ 1.48487944+0.j  0.62938661+0.j]\n [ 1.4881385 +0.j  0.97122795+0.j]\n [ 1.23197528+0.j  0.68701582+0.j]\n [ 1.14841112+0.j -0.04108548+0.j]\n [ 1.08849432+0.j  0.37384344+0.j]\n [ 1.27508967+0.j  0.92512745+0.j]\n [ 1.02809771+0.j  0.19545574+0.j]]\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_lda,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50899987+0.j, -0.4628191 +0.j],\n",
       "       [-1.79437621+0.j,  0.21551296+0.j],\n",
       "       [ 2.03142918+0.j, -0.10918847+0.j],\n",
       "       [ 0.57213737+0.j, -0.01643246+0.j],\n",
       "       [ 0.55131928+0.j, -0.28466316+0.j],\n",
       "       [-1.63299464+0.j,  0.08380076+0.j],\n",
       "       [ 0.08276354+0.j,  0.03921476+0.j],\n",
       "       [ 1.11034872+0.j,  0.78975895+0.j],\n",
       "       [ 0.7905682 +0.j, -0.53415646+0.j],\n",
       "       [ 0.20677791+0.j, -0.3015197 +0.j],\n",
       "       [ 0.96665283+0.j,  0.55094445+0.j],\n",
       "       [-1.60779243+0.j, -0.49470966+0.j],\n",
       "       [-1.90540375+0.j,  0.00699736+0.j],\n",
       "       [-1.61313608+0.j, -0.45035938+0.j],\n",
       "       [-1.78411878+0.j,  0.27552817+0.j],\n",
       "       [ 0.53051269+0.j,  0.32437035+0.j],\n",
       "       [ 1.50286834+0.j,  0.40706021+0.j],\n",
       "       [ 0.25579248+0.j, -0.55339018+0.j],\n",
       "       [ 0.54298136+0.j, -0.29872212+0.j],\n",
       "       [ 1.49547846+0.j,  0.31812788+0.j],\n",
       "       [-1.50436972+0.j, -0.30076849+0.j],\n",
       "       [ 0.89373762+0.j,  0.25361682+0.j],\n",
       "       [-1.51158303+0.j,  0.05541552+0.j],\n",
       "       [ 1.43560001+0.j,  0.21358258+0.j],\n",
       "       [ 1.1336934 +0.j,  0.61000586+0.j],\n",
       "       [ 1.23197528+0.j,  0.68701582+0.j],\n",
       "       [ 1.40904676+0.j, -0.3810563 +0.j],\n",
       "       [ 1.48487944+0.j,  0.62938661+0.j],\n",
       "       [-1.48803554+0.j, -0.28561905+0.j],\n",
       "       [-1.48607759+0.j, -0.37489461+0.j],\n",
       "       [-1.92638692+0.j,  0.17091452+0.j],\n",
       "       [-2.05091937+0.j,  0.822049  +0.j],\n",
       "       [ 0.2638771 +0.j,  0.05450089+0.j],\n",
       "       [-1.59518554+0.j, -0.15321155+0.j],\n",
       "       [-1.59744671+0.j, -0.21213628+0.j],\n",
       "       [ 1.14841112+0.j, -0.04108548+0.j],\n",
       "       [ 0.39072066+0.j,  0.20432354+0.j],\n",
       "       [-1.75296647+0.j, -0.05093196+0.j],\n",
       "       [-1.80228426+0.j,  0.05273823+0.j],\n",
       "       [-2.03106081+0.j,  0.28788886+0.j],\n",
       "       [ 1.2151613 +0.j,  0.07854975+0.j],\n",
       "       [ 0.45016923+0.j,  0.45758461+0.j],\n",
       "       [ 0.47106412+0.j,  0.07110928+0.j],\n",
       "       [-1.91304693+0.j,  0.51189714+0.j],\n",
       "       [-1.86185948+0.j,  0.09639322+0.j]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_lda = lda.transform(x_test)\n",
    "x_test_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
