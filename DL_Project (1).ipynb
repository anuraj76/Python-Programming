{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL Project.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTBOCpXHjfqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD6LtQMNj_qP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('loan_data.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzT6mFz1kjmI",
        "colab_type": "text"
      },
      "source": [
        "#Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3iHbbkbkFJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "3b96bd8b-9138-4640-a301-8f451fa90f0e"
      },
      "source": [
        "# What data looks like?\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit.policy</th>\n",
              "      <th>purpose</th>\n",
              "      <th>int.rate</th>\n",
              "      <th>installment</th>\n",
              "      <th>log.annual.inc</th>\n",
              "      <th>dti</th>\n",
              "      <th>fico</th>\n",
              "      <th>days.with.cr.line</th>\n",
              "      <th>revol.bal</th>\n",
              "      <th>revol.util</th>\n",
              "      <th>inq.last.6mths</th>\n",
              "      <th>delinq.2yrs</th>\n",
              "      <th>pub.rec</th>\n",
              "      <th>not.fully.paid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>0.1189</td>\n",
              "      <td>829.10</td>\n",
              "      <td>11.350407</td>\n",
              "      <td>19.48</td>\n",
              "      <td>737</td>\n",
              "      <td>5639.958333</td>\n",
              "      <td>28854</td>\n",
              "      <td>52.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>0.1071</td>\n",
              "      <td>228.22</td>\n",
              "      <td>11.082143</td>\n",
              "      <td>14.29</td>\n",
              "      <td>707</td>\n",
              "      <td>2760.000000</td>\n",
              "      <td>33623</td>\n",
              "      <td>76.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>0.1357</td>\n",
              "      <td>366.86</td>\n",
              "      <td>10.373491</td>\n",
              "      <td>11.63</td>\n",
              "      <td>682</td>\n",
              "      <td>4710.000000</td>\n",
              "      <td>3511</td>\n",
              "      <td>25.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>0.1008</td>\n",
              "      <td>162.34</td>\n",
              "      <td>11.350407</td>\n",
              "      <td>8.10</td>\n",
              "      <td>712</td>\n",
              "      <td>2699.958333</td>\n",
              "      <td>33667</td>\n",
              "      <td>73.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>0.1426</td>\n",
              "      <td>102.92</td>\n",
              "      <td>11.299732</td>\n",
              "      <td>14.97</td>\n",
              "      <td>667</td>\n",
              "      <td>4066.000000</td>\n",
              "      <td>4740</td>\n",
              "      <td>39.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   credit.policy             purpose  ...  pub.rec  not.fully.paid\n",
              "0              1  debt_consolidation  ...        0               0\n",
              "1              1         credit_card  ...        0               0\n",
              "2              1  debt_consolidation  ...        0               0\n",
              "3              1  debt_consolidation  ...        0               0\n",
              "4              1         credit_card  ...        0               0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4yqd_6RkvGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a90ff9cf-e096-49be-dfa3-9a075ea69a51"
      },
      "source": [
        "# How huge is our data?\n",
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9578, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR3G5ScllRNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "8301d077-7784-45cb-ed2a-1e2e948aac8a"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9578 entries, 0 to 9577\n",
            "Data columns (total 14 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   credit.policy      9578 non-null   int64  \n",
            " 1   purpose            9578 non-null   object \n",
            " 2   int.rate           9578 non-null   float64\n",
            " 3   installment        9578 non-null   float64\n",
            " 4   log.annual.inc     9578 non-null   float64\n",
            " 5   dti                9578 non-null   float64\n",
            " 6   fico               9578 non-null   int64  \n",
            " 7   days.with.cr.line  9578 non-null   float64\n",
            " 8   revol.bal          9578 non-null   int64  \n",
            " 9   revol.util         9578 non-null   float64\n",
            " 10  inq.last.6mths     9578 non-null   int64  \n",
            " 11  delinq.2yrs        9578 non-null   int64  \n",
            " 12  pub.rec            9578 non-null   int64  \n",
            " 13  not.fully.paid     9578 non-null   int64  \n",
            "dtypes: float64(6), int64(7), object(1)\n",
            "memory usage: 1.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEzeREnzulAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "ab974b5e-b223-407e-b84d-abe3ded1068b"
      },
      "source": [
        "#Lets get a statistical view of data\n",
        "data.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit.policy</th>\n",
              "      <th>int.rate</th>\n",
              "      <th>installment</th>\n",
              "      <th>log.annual.inc</th>\n",
              "      <th>dti</th>\n",
              "      <th>fico</th>\n",
              "      <th>days.with.cr.line</th>\n",
              "      <th>revol.bal</th>\n",
              "      <th>revol.util</th>\n",
              "      <th>inq.last.6mths</th>\n",
              "      <th>delinq.2yrs</th>\n",
              "      <th>pub.rec</th>\n",
              "      <th>not.fully.paid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>9578.000000</td>\n",
              "      <td>9578.000000</td>\n",
              "      <td>9578.000000</td>\n",
              "      <td>9578.000000</td>\n",
              "      <td>9578.000000</td>\n",
              "      <td>9578.000000</td>\n",
              "      <td>9578.000000</td>\n",
              "      <td>9.578000e+03</td>\n",
              "      <td>9578.000000</td>\n",
              "      <td>9578.000000</td>\n",
              "      <td>9578.000000</td>\n",
              "      <td>9578.000000</td>\n",
              "      <td>9578.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.804970</td>\n",
              "      <td>0.122640</td>\n",
              "      <td>319.089413</td>\n",
              "      <td>10.932117</td>\n",
              "      <td>12.606679</td>\n",
              "      <td>710.846314</td>\n",
              "      <td>4560.767197</td>\n",
              "      <td>1.691396e+04</td>\n",
              "      <td>46.799236</td>\n",
              "      <td>1.577469</td>\n",
              "      <td>0.163708</td>\n",
              "      <td>0.062122</td>\n",
              "      <td>0.160054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.396245</td>\n",
              "      <td>0.026847</td>\n",
              "      <td>207.071301</td>\n",
              "      <td>0.614813</td>\n",
              "      <td>6.883970</td>\n",
              "      <td>37.970537</td>\n",
              "      <td>2496.930377</td>\n",
              "      <td>3.375619e+04</td>\n",
              "      <td>29.014417</td>\n",
              "      <td>2.200245</td>\n",
              "      <td>0.546215</td>\n",
              "      <td>0.262126</td>\n",
              "      <td>0.366676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>15.670000</td>\n",
              "      <td>7.547502</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>612.000000</td>\n",
              "      <td>178.958333</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.103900</td>\n",
              "      <td>163.770000</td>\n",
              "      <td>10.558414</td>\n",
              "      <td>7.212500</td>\n",
              "      <td>682.000000</td>\n",
              "      <td>2820.000000</td>\n",
              "      <td>3.187000e+03</td>\n",
              "      <td>22.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.122100</td>\n",
              "      <td>268.950000</td>\n",
              "      <td>10.928884</td>\n",
              "      <td>12.665000</td>\n",
              "      <td>707.000000</td>\n",
              "      <td>4139.958333</td>\n",
              "      <td>8.596000e+03</td>\n",
              "      <td>46.300000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.140700</td>\n",
              "      <td>432.762500</td>\n",
              "      <td>11.291293</td>\n",
              "      <td>17.950000</td>\n",
              "      <td>737.000000</td>\n",
              "      <td>5730.000000</td>\n",
              "      <td>1.824950e+04</td>\n",
              "      <td>70.900000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.216400</td>\n",
              "      <td>940.140000</td>\n",
              "      <td>14.528354</td>\n",
              "      <td>29.960000</td>\n",
              "      <td>827.000000</td>\n",
              "      <td>17639.958330</td>\n",
              "      <td>1.207359e+06</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       credit.policy     int.rate  ...      pub.rec  not.fully.paid\n",
              "count    9578.000000  9578.000000  ...  9578.000000     9578.000000\n",
              "mean        0.804970     0.122640  ...     0.062122        0.160054\n",
              "std         0.396245     0.026847  ...     0.262126        0.366676\n",
              "min         0.000000     0.060000  ...     0.000000        0.000000\n",
              "25%         1.000000     0.103900  ...     0.000000        0.000000\n",
              "50%         1.000000     0.122100  ...     0.000000        0.000000\n",
              "75%         1.000000     0.140700  ...     0.000000        0.000000\n",
              "max         1.000000     0.216400  ...     5.000000        1.000000\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCPQLUIsux11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c342cb30-67b7-410d-b54b-74b606ec59a7"
      },
      "source": [
        "# Lets find out if there are any missing values\n",
        "\n",
        "data.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "credit.policy        0\n",
              "purpose              0\n",
              "int.rate             0\n",
              "installment          0\n",
              "log.annual.inc       0\n",
              "dti                  0\n",
              "fico                 0\n",
              "days.with.cr.line    0\n",
              "revol.bal            0\n",
              "revol.util           0\n",
              "inq.last.6mths       0\n",
              "delinq.2yrs          0\n",
              "pub.rec              0\n",
              "not.fully.paid       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ss8ybxFvksg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b06f638b-7407-48e0-dd8f-8e9648b37be6"
      },
      "source": [
        "data['credit.policy'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    7710\n",
              "0    1868\n",
              "Name: credit.policy, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woTaCw1GxKe9",
        "colab_type": "text"
      },
      "source": [
        "#### Note : As the data is unbalanced we could evaluate the model with Statistical approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W71SM9_6xvrJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "cf4ca547-3ae2-427f-be35-52dc7025a231"
      },
      "source": [
        "#lets find the pearson correlation between features (variables)\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "Corr = data.corr(method='pearson')\n",
        "Corr"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit.policy</th>\n",
              "      <th>int.rate</th>\n",
              "      <th>installment</th>\n",
              "      <th>log.annual.inc</th>\n",
              "      <th>dti</th>\n",
              "      <th>fico</th>\n",
              "      <th>days.with.cr.line</th>\n",
              "      <th>revol.bal</th>\n",
              "      <th>revol.util</th>\n",
              "      <th>inq.last.6mths</th>\n",
              "      <th>delinq.2yrs</th>\n",
              "      <th>pub.rec</th>\n",
              "      <th>not.fully.paid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>credit.policy</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.294089</td>\n",
              "      <td>0.058770</td>\n",
              "      <td>0.034906</td>\n",
              "      <td>-0.090901</td>\n",
              "      <td>0.348319</td>\n",
              "      <td>0.099026</td>\n",
              "      <td>-0.187518</td>\n",
              "      <td>-0.104095</td>\n",
              "      <td>-0.535511</td>\n",
              "      <td>-0.076318</td>\n",
              "      <td>-0.054243</td>\n",
              "      <td>-0.158119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>int.rate</th>\n",
              "      <td>-0.294089</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.276140</td>\n",
              "      <td>0.056383</td>\n",
              "      <td>0.220006</td>\n",
              "      <td>-0.714821</td>\n",
              "      <td>-0.124022</td>\n",
              "      <td>0.092527</td>\n",
              "      <td>0.464837</td>\n",
              "      <td>0.202780</td>\n",
              "      <td>0.156079</td>\n",
              "      <td>0.098162</td>\n",
              "      <td>0.159552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>installment</th>\n",
              "      <td>0.058770</td>\n",
              "      <td>0.276140</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.448102</td>\n",
              "      <td>0.050202</td>\n",
              "      <td>0.086039</td>\n",
              "      <td>0.183297</td>\n",
              "      <td>0.233625</td>\n",
              "      <td>0.081356</td>\n",
              "      <td>-0.010419</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.032760</td>\n",
              "      <td>0.049955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>log.annual.inc</th>\n",
              "      <td>0.034906</td>\n",
              "      <td>0.056383</td>\n",
              "      <td>0.448102</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.054065</td>\n",
              "      <td>0.114576</td>\n",
              "      <td>0.336896</td>\n",
              "      <td>0.372140</td>\n",
              "      <td>0.054881</td>\n",
              "      <td>0.029171</td>\n",
              "      <td>0.029203</td>\n",
              "      <td>0.016506</td>\n",
              "      <td>-0.033439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dti</th>\n",
              "      <td>-0.090901</td>\n",
              "      <td>0.220006</td>\n",
              "      <td>0.050202</td>\n",
              "      <td>-0.054065</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.241191</td>\n",
              "      <td>0.060101</td>\n",
              "      <td>0.188748</td>\n",
              "      <td>0.337109</td>\n",
              "      <td>0.029189</td>\n",
              "      <td>-0.021792</td>\n",
              "      <td>0.006209</td>\n",
              "      <td>0.037362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fico</th>\n",
              "      <td>0.348319</td>\n",
              "      <td>-0.714821</td>\n",
              "      <td>0.086039</td>\n",
              "      <td>0.114576</td>\n",
              "      <td>-0.241191</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.263880</td>\n",
              "      <td>-0.015553</td>\n",
              "      <td>-0.541289</td>\n",
              "      <td>-0.185293</td>\n",
              "      <td>-0.216340</td>\n",
              "      <td>-0.147592</td>\n",
              "      <td>-0.149666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>days.with.cr.line</th>\n",
              "      <td>0.099026</td>\n",
              "      <td>-0.124022</td>\n",
              "      <td>0.183297</td>\n",
              "      <td>0.336896</td>\n",
              "      <td>0.060101</td>\n",
              "      <td>0.263880</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.229344</td>\n",
              "      <td>-0.024239</td>\n",
              "      <td>-0.041736</td>\n",
              "      <td>0.081374</td>\n",
              "      <td>0.071826</td>\n",
              "      <td>-0.029237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>revol.bal</th>\n",
              "      <td>-0.187518</td>\n",
              "      <td>0.092527</td>\n",
              "      <td>0.233625</td>\n",
              "      <td>0.372140</td>\n",
              "      <td>0.188748</td>\n",
              "      <td>-0.015553</td>\n",
              "      <td>0.229344</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.203779</td>\n",
              "      <td>0.022394</td>\n",
              "      <td>-0.033243</td>\n",
              "      <td>-0.031010</td>\n",
              "      <td>0.053699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>revol.util</th>\n",
              "      <td>-0.104095</td>\n",
              "      <td>0.464837</td>\n",
              "      <td>0.081356</td>\n",
              "      <td>0.054881</td>\n",
              "      <td>0.337109</td>\n",
              "      <td>-0.541289</td>\n",
              "      <td>-0.024239</td>\n",
              "      <td>0.203779</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.013880</td>\n",
              "      <td>-0.042740</td>\n",
              "      <td>0.066717</td>\n",
              "      <td>0.082088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>inq.last.6mths</th>\n",
              "      <td>-0.535511</td>\n",
              "      <td>0.202780</td>\n",
              "      <td>-0.010419</td>\n",
              "      <td>0.029171</td>\n",
              "      <td>0.029189</td>\n",
              "      <td>-0.185293</td>\n",
              "      <td>-0.041736</td>\n",
              "      <td>0.022394</td>\n",
              "      <td>-0.013880</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.021245</td>\n",
              "      <td>0.072673</td>\n",
              "      <td>0.149452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delinq.2yrs</th>\n",
              "      <td>-0.076318</td>\n",
              "      <td>0.156079</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>0.029203</td>\n",
              "      <td>-0.021792</td>\n",
              "      <td>-0.216340</td>\n",
              "      <td>0.081374</td>\n",
              "      <td>-0.033243</td>\n",
              "      <td>-0.042740</td>\n",
              "      <td>0.021245</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.009184</td>\n",
              "      <td>0.008881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pub.rec</th>\n",
              "      <td>-0.054243</td>\n",
              "      <td>0.098162</td>\n",
              "      <td>-0.032760</td>\n",
              "      <td>0.016506</td>\n",
              "      <td>0.006209</td>\n",
              "      <td>-0.147592</td>\n",
              "      <td>0.071826</td>\n",
              "      <td>-0.031010</td>\n",
              "      <td>0.066717</td>\n",
              "      <td>0.072673</td>\n",
              "      <td>0.009184</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.048634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>not.fully.paid</th>\n",
              "      <td>-0.158119</td>\n",
              "      <td>0.159552</td>\n",
              "      <td>0.049955</td>\n",
              "      <td>-0.033439</td>\n",
              "      <td>0.037362</td>\n",
              "      <td>-0.149666</td>\n",
              "      <td>-0.029237</td>\n",
              "      <td>0.053699</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>0.149452</td>\n",
              "      <td>0.008881</td>\n",
              "      <td>0.048634</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   credit.policy  int.rate  ...   pub.rec  not.fully.paid\n",
              "credit.policy           1.000000 -0.294089  ... -0.054243       -0.158119\n",
              "int.rate               -0.294089  1.000000  ...  0.098162        0.159552\n",
              "installment             0.058770  0.276140  ... -0.032760        0.049955\n",
              "log.annual.inc          0.034906  0.056383  ...  0.016506       -0.033439\n",
              "dti                    -0.090901  0.220006  ...  0.006209        0.037362\n",
              "fico                    0.348319 -0.714821  ... -0.147592       -0.149666\n",
              "days.with.cr.line       0.099026 -0.124022  ...  0.071826       -0.029237\n",
              "revol.bal              -0.187518  0.092527  ... -0.031010        0.053699\n",
              "revol.util             -0.104095  0.464837  ...  0.066717        0.082088\n",
              "inq.last.6mths         -0.535511  0.202780  ...  0.072673        0.149452\n",
              "delinq.2yrs            -0.076318  0.156079  ...  0.009184        0.008881\n",
              "pub.rec                -0.054243  0.098162  ...  1.000000        0.048634\n",
              "not.fully.paid         -0.158119  0.159552  ...  0.048634        1.000000\n",
              "\n",
              "[13 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz1y7BakxvyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "ebae7e30-c4ca-48cf-e052-9d0596b72613"
      },
      "source": [
        "sns.heatmap(Corr)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4974e8eda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMHA7fqU21tn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "48629749-e093-4980-ad90-fa7843aa73fd"
      },
      "source": [
        "#In order to perform VIF we need to form a variable set of numerical features\n",
        "\n",
        "data.columns\n",
        "X = data.drop(['purpose'],axis=1)\n",
        "X.dtypes == 'object'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "credit.policy        False\n",
              "int.rate             False\n",
              "installment          False\n",
              "log.annual.inc       False\n",
              "dti                  False\n",
              "fico                 False\n",
              "days.with.cr.line    False\n",
              "revol.bal            False\n",
              "revol.util           False\n",
              "inq.last.6mths       False\n",
              "delinq.2yrs          False\n",
              "pub.rec              False\n",
              "not.fully.paid       False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cspMdTa5108g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets perform VIF to choose drop multicolinear variables\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
        "\n",
        "def calculate_vif_(X, thresh=5.0):\n",
        "    variables = list(range(X.shape[1]))\n",
        "    dropped = True\n",
        "    while dropped:\n",
        "        dropped = False\n",
        "        vif = [variance_inflation_factor(X.iloc[:, variables].values, ix)\n",
        "               for ix in range(X.iloc[:, variables].shape[1])]\n",
        "\n",
        "        maxloc = vif.index(max(vif))\n",
        "        if max(vif) > thresh:\n",
        "            print('dropping \\'' + X.iloc[:, variables].columns[maxloc] +\n",
        "                  '\\' at index: ' + str(maxloc))\n",
        "            del variables[maxloc]\n",
        "            dropped = True\n",
        "\n",
        "    print('Remaining variables:')\n",
        "    print(X.columns[variables])\n",
        "    return X.iloc[:, variables]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqHHcxvi11CI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "f40ed1be-4cea-42d4-a14e-dd97b7185927"
      },
      "source": [
        "calculate_vif_(X)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dropping 'log.annual.inc' at index: 3\n",
            "dropping 'fico' at index: 4\n",
            "dropping 'int.rate' at index: 1\n",
            "Remaining variables:\n",
            "Index(['credit.policy', 'installment', 'dti', 'days.with.cr.line', 'revol.bal',\n",
            "       'revol.util', 'inq.last.6mths', 'delinq.2yrs', 'pub.rec',\n",
            "       'not.fully.paid'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit.policy</th>\n",
              "      <th>installment</th>\n",
              "      <th>dti</th>\n",
              "      <th>days.with.cr.line</th>\n",
              "      <th>revol.bal</th>\n",
              "      <th>revol.util</th>\n",
              "      <th>inq.last.6mths</th>\n",
              "      <th>delinq.2yrs</th>\n",
              "      <th>pub.rec</th>\n",
              "      <th>not.fully.paid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>829.10</td>\n",
              "      <td>19.48</td>\n",
              "      <td>5639.958333</td>\n",
              "      <td>28854</td>\n",
              "      <td>52.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>228.22</td>\n",
              "      <td>14.29</td>\n",
              "      <td>2760.000000</td>\n",
              "      <td>33623</td>\n",
              "      <td>76.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>366.86</td>\n",
              "      <td>11.63</td>\n",
              "      <td>4710.000000</td>\n",
              "      <td>3511</td>\n",
              "      <td>25.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>162.34</td>\n",
              "      <td>8.10</td>\n",
              "      <td>2699.958333</td>\n",
              "      <td>33667</td>\n",
              "      <td>73.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>102.92</td>\n",
              "      <td>14.97</td>\n",
              "      <td>4066.000000</td>\n",
              "      <td>4740</td>\n",
              "      <td>39.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9573</th>\n",
              "      <td>0</td>\n",
              "      <td>344.76</td>\n",
              "      <td>10.39</td>\n",
              "      <td>10474.000000</td>\n",
              "      <td>215372</td>\n",
              "      <td>82.1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9574</th>\n",
              "      <td>0</td>\n",
              "      <td>257.70</td>\n",
              "      <td>0.21</td>\n",
              "      <td>4380.000000</td>\n",
              "      <td>184</td>\n",
              "      <td>1.1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9575</th>\n",
              "      <td>0</td>\n",
              "      <td>97.81</td>\n",
              "      <td>13.09</td>\n",
              "      <td>3450.041667</td>\n",
              "      <td>10036</td>\n",
              "      <td>82.9</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9576</th>\n",
              "      <td>0</td>\n",
              "      <td>351.58</td>\n",
              "      <td>19.18</td>\n",
              "      <td>1800.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9577</th>\n",
              "      <td>0</td>\n",
              "      <td>853.43</td>\n",
              "      <td>16.28</td>\n",
              "      <td>4740.000000</td>\n",
              "      <td>37879</td>\n",
              "      <td>57.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9578 rows  10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      credit.policy  installment    dti  ...  delinq.2yrs  pub.rec  not.fully.paid\n",
              "0                 1       829.10  19.48  ...            0        0               0\n",
              "1                 1       228.22  14.29  ...            0        0               0\n",
              "2                 1       366.86  11.63  ...            0        0               0\n",
              "3                 1       162.34   8.10  ...            0        0               0\n",
              "4                 1       102.92  14.97  ...            1        0               0\n",
              "...             ...          ...    ...  ...          ...      ...             ...\n",
              "9573              0       344.76  10.39  ...            0        0               1\n",
              "9574              0       257.70   0.21  ...            0        0               1\n",
              "9575              0        97.81  13.09  ...            0        0               1\n",
              "9576              0       351.58  19.18  ...            0        0               1\n",
              "9577              0       853.43  16.28  ...            0        0               1\n",
              "\n",
              "[9578 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAXdoq7p4WoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hence we need to drop of the muliticolinear variables from data\n",
        "\n",
        "data = data.drop(['log.annual.inc','fico','int.rate'],axis=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQTLeH2y5i4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "48d27cda-acf8-4533-d679-8492459ad1f1"
      },
      "source": [
        "data"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit.policy</th>\n",
              "      <th>purpose</th>\n",
              "      <th>installment</th>\n",
              "      <th>dti</th>\n",
              "      <th>days.with.cr.line</th>\n",
              "      <th>revol.bal</th>\n",
              "      <th>revol.util</th>\n",
              "      <th>inq.last.6mths</th>\n",
              "      <th>delinq.2yrs</th>\n",
              "      <th>pub.rec</th>\n",
              "      <th>not.fully.paid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>829.10</td>\n",
              "      <td>19.48</td>\n",
              "      <td>5639.958333</td>\n",
              "      <td>28854</td>\n",
              "      <td>52.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>228.22</td>\n",
              "      <td>14.29</td>\n",
              "      <td>2760.000000</td>\n",
              "      <td>33623</td>\n",
              "      <td>76.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>366.86</td>\n",
              "      <td>11.63</td>\n",
              "      <td>4710.000000</td>\n",
              "      <td>3511</td>\n",
              "      <td>25.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>162.34</td>\n",
              "      <td>8.10</td>\n",
              "      <td>2699.958333</td>\n",
              "      <td>33667</td>\n",
              "      <td>73.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>102.92</td>\n",
              "      <td>14.97</td>\n",
              "      <td>4066.000000</td>\n",
              "      <td>4740</td>\n",
              "      <td>39.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9573</th>\n",
              "      <td>0</td>\n",
              "      <td>all_other</td>\n",
              "      <td>344.76</td>\n",
              "      <td>10.39</td>\n",
              "      <td>10474.000000</td>\n",
              "      <td>215372</td>\n",
              "      <td>82.1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9574</th>\n",
              "      <td>0</td>\n",
              "      <td>all_other</td>\n",
              "      <td>257.70</td>\n",
              "      <td>0.21</td>\n",
              "      <td>4380.000000</td>\n",
              "      <td>184</td>\n",
              "      <td>1.1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9575</th>\n",
              "      <td>0</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>97.81</td>\n",
              "      <td>13.09</td>\n",
              "      <td>3450.041667</td>\n",
              "      <td>10036</td>\n",
              "      <td>82.9</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9576</th>\n",
              "      <td>0</td>\n",
              "      <td>home_improvement</td>\n",
              "      <td>351.58</td>\n",
              "      <td>19.18</td>\n",
              "      <td>1800.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9577</th>\n",
              "      <td>0</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>853.43</td>\n",
              "      <td>16.28</td>\n",
              "      <td>4740.000000</td>\n",
              "      <td>37879</td>\n",
              "      <td>57.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9578 rows  11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      credit.policy             purpose  ...  pub.rec  not.fully.paid\n",
              "0                 1  debt_consolidation  ...        0               0\n",
              "1                 1         credit_card  ...        0               0\n",
              "2                 1  debt_consolidation  ...        0               0\n",
              "3                 1  debt_consolidation  ...        0               0\n",
              "4                 1         credit_card  ...        0               0\n",
              "...             ...                 ...  ...      ...             ...\n",
              "9573              0           all_other  ...        0               1\n",
              "9574              0           all_other  ...        0               1\n",
              "9575              0  debt_consolidation  ...        0               1\n",
              "9576              0    home_improvement  ...        0               1\n",
              "9577              0  debt_consolidation  ...        0               1\n",
              "\n",
              "[9578 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jaH5rPXvV17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets divide our data into features and labels\n",
        "\n",
        "features = data.iloc[:,1:].values\n",
        "labels = data.iloc[:,0].values\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKzyJEXA5pnb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "3831e2b9-ab3b-4598-97ee-b52c7f4a5946"
      },
      "source": [
        "features"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['debt_consolidation', 829.1, 19.48, ..., 0, 0, 0],\n",
              "       ['credit_card', 228.22, 14.29, ..., 0, 0, 0],\n",
              "       ['debt_consolidation', 366.86, 11.63, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       ['debt_consolidation', 97.81, 13.09, ..., 0, 0, 1],\n",
              "       ['home_improvement', 351.58, 19.18, ..., 0, 0, 1],\n",
              "       ['debt_consolidation', 853.43, 16.28, ..., 0, 0, 1]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb0NZV8a7Xlv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2588cea3-9028-449c-e46f-52c844c88a5a"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9578, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF8yLjkk5rMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets perform One hot encoding for categorical features\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohepurpose = OneHotEncoder(sparse=False)\n",
        "fpurpose = ohepurpose.fit_transform(features[:,[0]].reshape(-1,1))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6fFqUpQAIxh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9ffa605d-8324-4e92-9267-e5ce17a81926"
      },
      "source": [
        "fpurpose"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvQ_Sirx6dD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concaetnate the fstate with features\n",
        "features = np.concatenate((features,fpurpose),axis=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r2MQ64B8ciB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30915b31-38f2-4ac9-8c56-f451db95d3ca"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9578, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1Y7sjHX89J2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64375cb5-788e-4676-cbcd-b32bcdd28006"
      },
      "source": [
        "features[0][0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'debt_consolidation'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiTQQFFC8YQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop the categorical columns\n",
        "\n",
        "features = np.delete(features, 0, 1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZTt-PcE8pLt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9a751a7d-da87-4ec2-c1f5-7a89174c4fb8"
      },
      "source": [
        "features"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[829.1, 19.48, 5639.958333, ..., 0.0, 0.0, 0.0],\n",
              "       [228.22, 14.29, 2760.0, ..., 0.0, 0.0, 0.0],\n",
              "       [366.86, 11.63, 4710.0, ..., 0.0, 0.0, 0.0],\n",
              "       ...,\n",
              "       [97.81, 13.09, 3450.041667, ..., 0.0, 0.0, 0.0],\n",
              "       [351.58, 19.18, 1800.0, ..., 1.0, 0.0, 0.0],\n",
              "       [853.43, 16.28, 4740.0, ..., 0.0, 0.0, 0.0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz2IoLKK8qYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Standardization for features\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scfeatures = StandardScaler()\n",
        "\n",
        "features = scfeatures.fit_transform(features)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPhWqI489YcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#As we have to build a deep learning Model,Hence standardization of labels is neccessary\n",
        "\n",
        "#Standardization for labels\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#le_credit_policy = LabelEncoder()\n",
        "#labels = le_credit_policy.fit_transform(labels)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ypw3MHH9uTl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8940d0be-6013-47fc-898c-6dd843637823"
      },
      "source": [
        "labels"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NQTi_Ei9z8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to create dummy variables we can use Keras Functionality\n",
        "#import tensorflow as tf\n",
        "\n",
        "#ohelables = tf.keras.utils.to_categorical(labels)\n",
        "#ohelables"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxHjm0Ln-D2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "948ae302-dbb5-4764-db12-38e975af6377"
      },
      "source": [
        "features.ndim"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB_keKqB-IKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5907ccdb-b9a5-4c64-80f6-2e88d7d7c00a"
      },
      "source": [
        "labels.ndim"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foQt2km4EaEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to reshape the labels\n",
        "labels = labels.reshape(-1,1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh-TGjS9-KDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=50)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKU0SxfT_jvS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f920ecd8-f2de-42d6-b6b5-3738d8509bed"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7662, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-26TET1-62n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8b8afa3f-87ed-484e-9906-f474075ea87e"
      },
      "source": [
        "print('Training data Shape:',X_train.shape)\n",
        "print('Testing data Shape:',X_test.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data Shape: (7662, 16)\n",
            "Testing data Shape: (1916, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP_tQo8U_TP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modelling\n",
        "\n",
        "#1.Architect the model\n",
        "import tensorflow as tf\n",
        "\n",
        "#Step 1: Create a Sequential Model Object\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Step2: Create Input Layer\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Dense( units=60,activation='relu',kernel_initializer=tf.keras.initializers.GlorotUniform(),input_shape=(16,) ))\n",
        "model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense( units=60,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0,stddev=1),bias_initializer=tf.keras.initializers.GlorotUniform(),activation='relu'))\n",
        "model.add(tf.keras.layers.Dense( units=1,activation='sigmoid'))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-H5vPAsBgk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model Compliation\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False, name='RMSprop'),loss='binary_crossentropy', metrics=[\"accuracy\"])"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIKnQU_RB_aj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6144987e-8de5-4018-b572-ca1c06f9dd72"
      },
      "source": [
        "# MOdel Fitting\n",
        "\n",
        "model.fit(X_train,y_train,epochs=1000, validation_data=(X_test,y_test))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "240/240 [==============================] - 1s 3ms/step - loss: 7.9450e-12 - accuracy: 1.0000 - val_loss: 7.5643 - val_accuracy: 0.8951\n",
            "Epoch 2/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 7.5257e-11 - accuracy: 1.0000 - val_loss: 8.5781 - val_accuracy: 0.8977\n",
            "Epoch 3/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.9143 - val_loss: 0.2922 - val_accuracy: 0.8904\n",
            "Epoch 4/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.2591 - accuracy: 0.9115 - val_loss: 0.4793 - val_accuracy: 0.8779\n",
            "Epoch 5/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.9096 - val_loss: 0.2836 - val_accuracy: 0.9066\n",
            "Epoch 6/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.2561 - accuracy: 0.9174 - val_loss: 0.2958 - val_accuracy: 0.8993\n",
            "Epoch 7/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.2979 - accuracy: 0.9131 - val_loss: 0.2973 - val_accuracy: 0.9003\n",
            "Epoch 8/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.2569 - accuracy: 0.9163 - val_loss: 0.2924 - val_accuracy: 0.8935\n",
            "Epoch 9/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.9192 - val_loss: 0.3365 - val_accuracy: 0.8982\n",
            "Epoch 10/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.9122 - val_loss: 0.3725 - val_accuracy: 0.8925\n",
            "Epoch 11/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3483 - accuracy: 0.9165 - val_loss: 0.2956 - val_accuracy: 0.8998\n",
            "Epoch 12/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.4498 - accuracy: 0.9085 - val_loss: 0.2842 - val_accuracy: 0.8977\n",
            "Epoch 13/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3226 - accuracy: 0.9144 - val_loss: 0.3023 - val_accuracy: 0.8977\n",
            "Epoch 14/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.2595 - accuracy: 0.9166 - val_loss: 0.3403 - val_accuracy: 0.8925\n",
            "Epoch 15/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.2863 - accuracy: 0.9050 - val_loss: 0.3090 - val_accuracy: 0.9055\n",
            "Epoch 16/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.9122 - val_loss: 0.3003 - val_accuracy: 0.8909\n",
            "Epoch 17/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3127 - accuracy: 0.9069 - val_loss: 0.3412 - val_accuracy: 0.8904\n",
            "Epoch 18/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.2993 - accuracy: 0.9077 - val_loss: 0.3079 - val_accuracy: 0.8935\n",
            "Epoch 19/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.2932 - accuracy: 0.9085 - val_loss: 0.3462 - val_accuracy: 0.8857\n",
            "Epoch 20/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3132 - accuracy: 0.9063 - val_loss: 0.3205 - val_accuracy: 0.8920\n",
            "Epoch 21/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3392 - accuracy: 0.8982 - val_loss: 0.3584 - val_accuracy: 0.8862\n",
            "Epoch 22/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.4216 - accuracy: 0.9003 - val_loss: 0.3661 - val_accuracy: 0.8883\n",
            "Epoch 23/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.4255 - accuracy: 0.8682 - val_loss: 0.3615 - val_accuracy: 0.8810\n",
            "Epoch 24/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.4084 - accuracy: 0.8743 - val_loss: 0.3722 - val_accuracy: 0.8894\n",
            "Epoch 25/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.4017 - accuracy: 0.8797 - val_loss: 0.3893 - val_accuracy: 0.8659\n",
            "Epoch 26/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.4156 - accuracy: 0.8662 - val_loss: 0.3626 - val_accuracy: 0.8867\n",
            "Epoch 27/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3576 - accuracy: 0.8926 - val_loss: 0.3626 - val_accuracy: 0.8820\n",
            "Epoch 28/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.4339 - accuracy: 0.8936 - val_loss: 1.1133 - val_accuracy: 0.8894\n",
            "Epoch 29/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3913 - accuracy: 0.8902 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 30/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3549 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 31/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3544 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 32/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 33/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8865 - val_loss: 0.3930 - val_accuracy: 0.8700\n",
            "Epoch 34/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8865 - val_loss: 0.3984 - val_accuracy: 0.8700\n",
            "Epoch 35/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8865 - val_loss: 0.3958 - val_accuracy: 0.8700\n",
            "Epoch 36/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8865 - val_loss: 0.3964 - val_accuracy: 0.8700\n",
            "Epoch 37/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 38/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8865 - val_loss: 0.3862 - val_accuracy: 0.8700\n",
            "Epoch 39/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8865 - val_loss: 0.3916 - val_accuracy: 0.8700\n",
            "Epoch 40/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 41/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 42/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8865 - val_loss: 0.3915 - val_accuracy: 0.8700\n",
            "Epoch 43/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 44/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 45/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8865 - val_loss: 0.3862 - val_accuracy: 0.8700\n",
            "Epoch 46/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8865 - val_loss: 0.3942 - val_accuracy: 0.8700\n",
            "Epoch 47/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8865 - val_loss: 0.3920 - val_accuracy: 0.8700\n",
            "Epoch 48/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8865 - val_loss: 0.3961 - val_accuracy: 0.8700\n",
            "Epoch 49/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 50/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 51/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8865 - val_loss: 0.3868 - val_accuracy: 0.8700\n",
            "Epoch 52/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8865 - val_loss: 0.3906 - val_accuracy: 0.8700\n",
            "Epoch 53/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3861 - val_accuracy: 0.8700\n",
            "Epoch 54/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 55/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8865 - val_loss: 0.3942 - val_accuracy: 0.8700\n",
            "Epoch 56/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3990 - val_accuracy: 0.8700\n",
            "Epoch 57/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 58/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 59/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8865 - val_loss: 0.3872 - val_accuracy: 0.8700\n",
            "Epoch 60/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8865 - val_loss: 0.3916 - val_accuracy: 0.8700\n",
            "Epoch 61/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 62/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8865 - val_loss: 0.3934 - val_accuracy: 0.8700\n",
            "Epoch 63/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8865 - val_loss: 0.3915 - val_accuracy: 0.8700\n",
            "Epoch 64/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 65/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 66/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8865 - val_loss: 0.3962 - val_accuracy: 0.8700\n",
            "Epoch 67/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 68/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 69/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 70/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 71/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3865 - val_accuracy: 0.8700\n",
            "Epoch 72/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 73/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8865 - val_loss: 0.3915 - val_accuracy: 0.8700\n",
            "Epoch 74/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 75/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 76/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3959 - val_accuracy: 0.8700\n",
            "Epoch 77/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 78/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8865 - val_loss: 0.3860 - val_accuracy: 0.8700\n",
            "Epoch 79/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 80/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8865 - val_loss: 0.4037 - val_accuracy: 0.8700\n",
            "Epoch 81/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 82/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3946 - val_accuracy: 0.8700\n",
            "Epoch 83/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8865 - val_loss: 0.3950 - val_accuracy: 0.8700\n",
            "Epoch 84/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 85/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 86/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 87/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 88/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3918 - val_accuracy: 0.8700\n",
            "Epoch 89/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3538 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 90/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8865 - val_loss: 0.3932 - val_accuracy: 0.8700\n",
            "Epoch 91/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 92/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 93/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 94/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3962 - val_accuracy: 0.8700\n",
            "Epoch 95/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 96/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 97/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 98/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3982 - val_accuracy: 0.8700\n",
            "Epoch 99/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3903 - val_accuracy: 0.8700\n",
            "Epoch 100/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3864 - val_accuracy: 0.8700\n",
            "Epoch 101/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 102/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8865 - val_loss: 0.3970 - val_accuracy: 0.8700\n",
            "Epoch 103/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3536 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 104/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 105/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 106/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 107/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 108/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 109/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 110/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3910 - val_accuracy: 0.8700\n",
            "Epoch 111/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3864 - val_accuracy: 0.8700\n",
            "Epoch 112/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 113/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 114/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 115/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 116/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 117/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 118/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 119/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 120/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3920 - val_accuracy: 0.8700\n",
            "Epoch 121/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3928 - val_accuracy: 0.8700\n",
            "Epoch 122/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3540 - accuracy: 0.8865 - val_loss: 0.3863 - val_accuracy: 0.8700\n",
            "Epoch 123/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 124/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 125/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3921 - val_accuracy: 0.8700\n",
            "Epoch 126/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3926 - val_accuracy: 0.8700\n",
            "Epoch 127/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 128/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3935 - val_accuracy: 0.8700\n",
            "Epoch 129/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
            "Epoch 130/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3906 - val_accuracy: 0.8700\n",
            "Epoch 131/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 132/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
            "Epoch 133/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 134/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 135/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3933 - val_accuracy: 0.8700\n",
            "Epoch 136/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 137/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3947 - val_accuracy: 0.8700\n",
            "Epoch 138/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3927 - val_accuracy: 0.8700\n",
            "Epoch 139/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 140/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3921 - val_accuracy: 0.8700\n",
            "Epoch 141/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3923 - val_accuracy: 0.8700\n",
            "Epoch 142/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 143/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 144/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3915 - val_accuracy: 0.8700\n",
            "Epoch 145/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 146/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 147/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 148/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 149/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 150/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
            "Epoch 151/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 152/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 153/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3865 - val_accuracy: 0.8700\n",
            "Epoch 154/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 155/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3993 - val_accuracy: 0.8700\n",
            "Epoch 156/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3868 - val_accuracy: 0.8700\n",
            "Epoch 157/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 158/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 159/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 160/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 161/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 162/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
            "Epoch 163/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 164/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3931 - val_accuracy: 0.8700\n",
            "Epoch 165/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3934 - val_accuracy: 0.8700\n",
            "Epoch 166/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 167/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8865 - val_loss: 0.3966 - val_accuracy: 0.8700\n",
            "Epoch 168/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 169/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 170/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 171/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
            "Epoch 172/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 173/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 174/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3870 - val_accuracy: 0.8700\n",
            "Epoch 175/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3872 - val_accuracy: 0.8700\n",
            "Epoch 176/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 177/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 178/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 179/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 180/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 181/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 182/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
            "Epoch 183/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 184/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3866 - val_accuracy: 0.8700\n",
            "Epoch 185/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3861 - val_accuracy: 0.8700\n",
            "Epoch 186/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3865 - val_accuracy: 0.8700\n",
            "Epoch 187/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 188/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 189/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 190/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 191/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 192/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3916 - val_accuracy: 0.8700\n",
            "Epoch 193/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 194/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 195/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 196/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 197/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 198/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 199/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3937 - val_accuracy: 0.8700\n",
            "Epoch 200/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 201/1000\n",
            "240/240 [==============================] - 1s 3ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3987 - val_accuracy: 0.8700\n",
            "Epoch 202/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 203/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3948 - val_accuracy: 0.8700\n",
            "Epoch 204/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3964 - val_accuracy: 0.8700\n",
            "Epoch 205/1000\n",
            "240/240 [==============================] - 1s 3ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 206/1000\n",
            "240/240 [==============================] - 1s 3ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 207/1000\n",
            "240/240 [==============================] - 1s 3ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 208/1000\n",
            "240/240 [==============================] - 1s 3ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 209/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 210/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 211/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 212/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 213/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 214/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3912 - val_accuracy: 0.8700\n",
            "Epoch 215/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3921 - val_accuracy: 0.8700\n",
            "Epoch 216/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3916 - val_accuracy: 0.8700\n",
            "Epoch 217/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3925 - val_accuracy: 0.8700\n",
            "Epoch 218/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
            "Epoch 219/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3961 - val_accuracy: 0.8700\n",
            "Epoch 220/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 221/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 222/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 223/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3925 - val_accuracy: 0.8700\n",
            "Epoch 224/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3924 - val_accuracy: 0.8700\n",
            "Epoch 225/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3953 - val_accuracy: 0.8700\n",
            "Epoch 226/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3951 - val_accuracy: 0.8700\n",
            "Epoch 227/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 228/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 229/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3920 - val_accuracy: 0.8700\n",
            "Epoch 230/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 231/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 232/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3538 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 233/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 234/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 235/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 236/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3903 - val_accuracy: 0.8700\n",
            "Epoch 237/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3912 - val_accuracy: 0.8700\n",
            "Epoch 238/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 239/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 240/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 241/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
            "Epoch 242/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 243/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 244/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3930 - val_accuracy: 0.8700\n",
            "Epoch 245/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 246/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3951 - val_accuracy: 0.8700\n",
            "Epoch 247/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 248/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 249/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 250/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 251/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 252/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 253/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 254/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3932 - val_accuracy: 0.8700\n",
            "Epoch 255/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3907 - val_accuracy: 0.8700\n",
            "Epoch 256/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 257/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 258/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3922 - val_accuracy: 0.8700\n",
            "Epoch 259/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 260/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3937 - val_accuracy: 0.8700\n",
            "Epoch 261/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 262/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 263/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 264/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3975 - val_accuracy: 0.8700\n",
            "Epoch 265/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 266/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3960 - val_accuracy: 0.8700\n",
            "Epoch 267/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3911 - val_accuracy: 0.8700\n",
            "Epoch 268/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3924 - val_accuracy: 0.8700\n",
            "Epoch 269/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 270/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 271/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 272/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3917 - val_accuracy: 0.8700\n",
            "Epoch 273/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3981 - val_accuracy: 0.8700\n",
            "Epoch 274/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3924 - val_accuracy: 0.8700\n",
            "Epoch 275/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 276/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3920 - val_accuracy: 0.8700\n",
            "Epoch 277/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3943 - val_accuracy: 0.8700\n",
            "Epoch 278/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 279/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 280/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 281/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 282/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3989 - val_accuracy: 0.8700\n",
            "Epoch 283/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3864 - val_accuracy: 0.8700\n",
            "Epoch 284/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 285/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 286/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 287/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 288/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 289/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 290/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3936 - val_accuracy: 0.8700\n",
            "Epoch 291/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3948 - val_accuracy: 0.8700\n",
            "Epoch 292/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3906 - val_accuracy: 0.8700\n",
            "Epoch 293/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 294/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3941 - val_accuracy: 0.8700\n",
            "Epoch 295/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 296/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 297/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 298/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 299/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 300/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 301/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 302/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 303/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3928 - val_accuracy: 0.8700\n",
            "Epoch 304/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 305/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 306/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 307/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 308/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 309/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3865 - val_accuracy: 0.8700\n",
            "Epoch 310/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3872 - val_accuracy: 0.8700\n",
            "Epoch 311/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 312/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 313/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 314/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 315/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 316/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 317/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 318/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 319/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3916 - val_accuracy: 0.8700\n",
            "Epoch 320/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3868 - val_accuracy: 0.8700\n",
            "Epoch 321/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3917 - val_accuracy: 0.8700\n",
            "Epoch 322/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 323/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 324/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 325/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 326/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3973 - val_accuracy: 0.8700\n",
            "Epoch 327/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 328/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 329/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3932 - val_accuracy: 0.8700\n",
            "Epoch 330/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 331/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 332/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3917 - val_accuracy: 0.8700\n",
            "Epoch 333/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 334/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 335/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 336/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 337/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3941 - val_accuracy: 0.8700\n",
            "Epoch 338/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 339/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 340/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 341/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3903 - val_accuracy: 0.8700\n",
            "Epoch 342/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 343/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 344/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 345/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 346/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3926 - val_accuracy: 0.8700\n",
            "Epoch 347/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3957 - val_accuracy: 0.8700\n",
            "Epoch 348/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3870 - val_accuracy: 0.8700\n",
            "Epoch 349/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3960 - val_accuracy: 0.8700\n",
            "Epoch 350/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 351/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 352/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 353/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 354/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 355/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3868 - val_accuracy: 0.8700\n",
            "Epoch 356/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3923 - val_accuracy: 0.8700\n",
            "Epoch 357/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 358/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 359/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3865 - val_accuracy: 0.8700\n",
            "Epoch 360/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8865 - val_loss: 0.3961 - val_accuracy: 0.8700\n",
            "Epoch 361/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 362/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3924 - val_accuracy: 0.8700\n",
            "Epoch 363/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 364/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 365/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 366/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3935 - val_accuracy: 0.8700\n",
            "Epoch 367/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 368/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3906 - val_accuracy: 0.8700\n",
            "Epoch 369/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3919 - val_accuracy: 0.8700\n",
            "Epoch 370/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 371/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 372/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3970 - val_accuracy: 0.8700\n",
            "Epoch 373/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8865 - val_loss: 0.3911 - val_accuracy: 0.8700\n",
            "Epoch 374/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3921 - val_accuracy: 0.8700\n",
            "Epoch 375/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3914 - val_accuracy: 0.8700\n",
            "Epoch 376/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3966 - val_accuracy: 0.8700\n",
            "Epoch 377/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 378/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 379/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 380/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3915 - val_accuracy: 0.8700\n",
            "Epoch 381/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 382/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 383/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 384/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 385/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 386/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 387/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 388/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3921 - val_accuracy: 0.8700\n",
            "Epoch 389/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 390/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 391/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 392/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3912 - val_accuracy: 0.8700\n",
            "Epoch 393/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 394/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 395/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 396/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 397/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 398/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 399/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 400/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 401/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 402/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 403/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3918 - val_accuracy: 0.8700\n",
            "Epoch 404/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 405/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 406/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 407/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 408/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 409/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 410/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 411/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 412/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3937 - val_accuracy: 0.8700\n",
            "Epoch 413/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 414/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 415/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 416/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
            "Epoch 417/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 418/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3872 - val_accuracy: 0.8700\n",
            "Epoch 419/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3907 - val_accuracy: 0.8700\n",
            "Epoch 420/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 421/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 422/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3923 - val_accuracy: 0.8700\n",
            "Epoch 423/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 424/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 425/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 426/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 427/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 428/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3868 - val_accuracy: 0.8700\n",
            "Epoch 429/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 430/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 431/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 432/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3916 - val_accuracy: 0.8700\n",
            "Epoch 433/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 434/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 435/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
            "Epoch 436/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 437/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3933 - val_accuracy: 0.8700\n",
            "Epoch 438/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 439/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 440/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3923 - val_accuracy: 0.8700\n",
            "Epoch 441/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 442/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 443/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 444/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 445/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 446/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 447/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3914 - val_accuracy: 0.8700\n",
            "Epoch 448/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 449/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 450/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3926 - val_accuracy: 0.8700\n",
            "Epoch 451/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 452/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 453/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 454/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 455/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 456/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 457/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3906 - val_accuracy: 0.8700\n",
            "Epoch 458/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 459/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 460/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3907 - val_accuracy: 0.8700\n",
            "Epoch 461/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 462/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 463/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3863 - val_accuracy: 0.8700\n",
            "Epoch 464/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 465/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 466/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 467/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3872 - val_accuracy: 0.8700\n",
            "Epoch 468/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 469/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 470/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 471/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 472/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 473/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 474/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3870 - val_accuracy: 0.8700\n",
            "Epoch 475/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 476/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 477/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 478/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 479/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 480/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3943 - val_accuracy: 0.8700\n",
            "Epoch 481/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 482/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 483/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 484/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 485/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3925 - val_accuracy: 0.8700\n",
            "Epoch 486/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 487/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 488/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3907 - val_accuracy: 0.8700\n",
            "Epoch 489/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3930 - val_accuracy: 0.8700\n",
            "Epoch 490/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 491/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 492/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3870 - val_accuracy: 0.8700\n",
            "Epoch 493/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 494/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3925 - val_accuracy: 0.8700\n",
            "Epoch 495/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3940 - val_accuracy: 0.8700\n",
            "Epoch 496/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 497/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 498/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 499/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 500/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 501/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3912 - val_accuracy: 0.8700\n",
            "Epoch 502/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 503/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3934 - val_accuracy: 0.8700\n",
            "Epoch 504/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 505/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
            "Epoch 506/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 507/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 508/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 509/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
            "Epoch 510/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 511/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 512/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3952 - val_accuracy: 0.8700\n",
            "Epoch 513/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3935 - val_accuracy: 0.8700\n",
            "Epoch 514/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 515/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 516/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 517/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 518/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3930 - val_accuracy: 0.8700\n",
            "Epoch 519/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3903 - val_accuracy: 0.8700\n",
            "Epoch 520/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3920 - val_accuracy: 0.8700\n",
            "Epoch 521/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3911 - val_accuracy: 0.8700\n",
            "Epoch 522/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 523/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 524/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 525/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
            "Epoch 526/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 527/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3907 - val_accuracy: 0.8700\n",
            "Epoch 528/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 529/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 530/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3906 - val_accuracy: 0.8700\n",
            "Epoch 531/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3918 - val_accuracy: 0.8700\n",
            "Epoch 532/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 533/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 534/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 535/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 536/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 537/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3910 - val_accuracy: 0.8700\n",
            "Epoch 538/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 539/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 540/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3910 - val_accuracy: 0.8700\n",
            "Epoch 541/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8865 - val_loss: 0.3992 - val_accuracy: 0.8700\n",
            "Epoch 542/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 543/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 544/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 545/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 546/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3914 - val_accuracy: 0.8700\n",
            "Epoch 547/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 548/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 549/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3920 - val_accuracy: 0.8700\n",
            "Epoch 550/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 551/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3933 - val_accuracy: 0.8700\n",
            "Epoch 552/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 553/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 554/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 555/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3923 - val_accuracy: 0.8700\n",
            "Epoch 556/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3914 - val_accuracy: 0.8700\n",
            "Epoch 557/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3863 - val_accuracy: 0.8700\n",
            "Epoch 558/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 559/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 560/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 561/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 562/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3906 - val_accuracy: 0.8700\n",
            "Epoch 563/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 564/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3865 - val_accuracy: 0.8700\n",
            "Epoch 565/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 566/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 567/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 568/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 569/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3872 - val_accuracy: 0.8700\n",
            "Epoch 570/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 571/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3932 - val_accuracy: 0.8700\n",
            "Epoch 572/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3863 - val_accuracy: 0.8700\n",
            "Epoch 573/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 574/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3938 - val_accuracy: 0.8700\n",
            "Epoch 575/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3923 - val_accuracy: 0.8700\n",
            "Epoch 576/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 577/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3922 - val_accuracy: 0.8700\n",
            "Epoch 578/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 579/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 580/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3935 - val_accuracy: 0.8700\n",
            "Epoch 581/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 582/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3864 - val_accuracy: 0.8700\n",
            "Epoch 583/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 584/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3872 - val_accuracy: 0.8700\n",
            "Epoch 585/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3920 - val_accuracy: 0.8700\n",
            "Epoch 586/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3915 - val_accuracy: 0.8700\n",
            "Epoch 587/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 588/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 589/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 590/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 591/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 592/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 593/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 594/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 595/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3866 - val_accuracy: 0.8700\n",
            "Epoch 596/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 597/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 598/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 599/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 600/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 601/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3922 - val_accuracy: 0.8700\n",
            "Epoch 602/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 603/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 604/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3906 - val_accuracy: 0.8700\n",
            "Epoch 605/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3907 - val_accuracy: 0.8700\n",
            "Epoch 606/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 607/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 608/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 609/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3906 - val_accuracy: 0.8700\n",
            "Epoch 610/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 611/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 612/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 613/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3941 - val_accuracy: 0.8700\n",
            "Epoch 614/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3872 - val_accuracy: 0.8700\n",
            "Epoch 615/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 616/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 617/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 618/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3903 - val_accuracy: 0.8700\n",
            "Epoch 619/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 620/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 621/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 622/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3865 - val_accuracy: 0.8700\n",
            "Epoch 623/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 624/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 625/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 626/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 627/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
            "Epoch 628/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 629/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
            "Epoch 630/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3916 - val_accuracy: 0.8700\n",
            "Epoch 631/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 632/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 633/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 634/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3937 - val_accuracy: 0.8700\n",
            "Epoch 635/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 636/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 637/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 638/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 639/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 640/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8865 - val_loss: 0.3952 - val_accuracy: 0.8700\n",
            "Epoch 641/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 642/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3912 - val_accuracy: 0.8700\n",
            "Epoch 643/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3954 - val_accuracy: 0.8700\n",
            "Epoch 644/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 645/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 646/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 647/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3966 - val_accuracy: 0.8700\n",
            "Epoch 648/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3870 - val_accuracy: 0.8700\n",
            "Epoch 649/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
            "Epoch 650/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 651/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8865 - val_loss: 0.4036 - val_accuracy: 0.8700\n",
            "Epoch 652/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 653/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3922 - val_accuracy: 0.8700\n",
            "Epoch 654/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 655/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 656/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 657/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 658/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3923 - val_accuracy: 0.8700\n",
            "Epoch 659/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 660/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 661/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 662/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 663/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 664/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 665/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 666/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3921 - val_accuracy: 0.8700\n",
            "Epoch 667/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 668/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 669/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 670/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 671/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 672/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 673/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 674/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 675/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3936 - val_accuracy: 0.8700\n",
            "Epoch 676/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 677/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 678/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 679/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 680/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3866 - val_accuracy: 0.8700\n",
            "Epoch 681/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 682/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 683/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3925 - val_accuracy: 0.8700\n",
            "Epoch 684/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 685/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 686/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3928 - val_accuracy: 0.8700\n",
            "Epoch 687/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 688/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3920 - val_accuracy: 0.8700\n",
            "Epoch 689/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 690/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3911 - val_accuracy: 0.8700\n",
            "Epoch 691/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 692/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 693/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 694/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 695/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 696/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 697/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 698/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8865 - val_loss: 0.4000 - val_accuracy: 0.8700\n",
            "Epoch 699/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 700/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3920 - val_accuracy: 0.8700\n",
            "Epoch 701/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 702/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 703/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 704/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 705/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 706/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3911 - val_accuracy: 0.8700\n",
            "Epoch 707/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 708/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3866 - val_accuracy: 0.8700\n",
            "Epoch 709/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 710/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 711/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 712/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 713/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3967 - val_accuracy: 0.8700\n",
            "Epoch 714/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3917 - val_accuracy: 0.8700\n",
            "Epoch 715/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 716/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 717/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3918 - val_accuracy: 0.8700\n",
            "Epoch 718/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 719/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 720/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 721/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 722/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 723/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3939 - val_accuracy: 0.8700\n",
            "Epoch 724/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3920 - val_accuracy: 0.8700\n",
            "Epoch 725/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3917 - val_accuracy: 0.8700\n",
            "Epoch 726/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 727/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 728/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 729/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 730/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 731/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3942 - val_accuracy: 0.8700\n",
            "Epoch 732/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3522 - accuracy: 0.8865 - val_loss: 0.3923 - val_accuracy: 0.8700\n",
            "Epoch 733/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 734/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3923 - val_accuracy: 0.8700\n",
            "Epoch 735/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3872 - val_accuracy: 0.8700\n",
            "Epoch 736/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3943 - val_accuracy: 0.8700\n",
            "Epoch 737/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 738/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 739/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 740/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 741/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 742/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 743/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 744/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 745/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 746/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
            "Epoch 747/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3930 - val_accuracy: 0.8700\n",
            "Epoch 748/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3931 - val_accuracy: 0.8700\n",
            "Epoch 749/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 750/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 751/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3918 - val_accuracy: 0.8700\n",
            "Epoch 752/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3870 - val_accuracy: 0.8700\n",
            "Epoch 753/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3910 - val_accuracy: 0.8700\n",
            "Epoch 754/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3949 - val_accuracy: 0.8700\n",
            "Epoch 755/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 756/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 757/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 758/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3960 - val_accuracy: 0.8700\n",
            "Epoch 759/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 760/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 761/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 762/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 763/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 764/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 765/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3907 - val_accuracy: 0.8700\n",
            "Epoch 766/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 767/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 768/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3911 - val_accuracy: 0.8700\n",
            "Epoch 769/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3919 - val_accuracy: 0.8700\n",
            "Epoch 770/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 771/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3907 - val_accuracy: 0.8700\n",
            "Epoch 772/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3914 - val_accuracy: 0.8700\n",
            "Epoch 773/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3911 - val_accuracy: 0.8700\n",
            "Epoch 774/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 775/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 776/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 777/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 778/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8865 - val_loss: 0.4060 - val_accuracy: 0.8700\n",
            "Epoch 779/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 780/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
            "Epoch 781/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 782/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3862 - val_accuracy: 0.8700\n",
            "Epoch 783/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3920 - val_accuracy: 0.8700\n",
            "Epoch 784/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
            "Epoch 785/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 786/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3935 - val_accuracy: 0.8700\n",
            "Epoch 787/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3937 - val_accuracy: 0.8700\n",
            "Epoch 788/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 789/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 790/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 791/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8865 - val_loss: 0.3952 - val_accuracy: 0.8700\n",
            "Epoch 792/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 793/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3919 - val_accuracy: 0.8700\n",
            "Epoch 794/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 795/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8865 - val_loss: 0.3912 - val_accuracy: 0.8700\n",
            "Epoch 796/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8865 - val_loss: 0.3911 - val_accuracy: 0.8700\n",
            "Epoch 797/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3922 - val_accuracy: 0.8700\n",
            "Epoch 798/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 799/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 800/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 801/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3924 - val_accuracy: 0.8700\n",
            "Epoch 802/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 803/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 804/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 805/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 806/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3903 - val_accuracy: 0.8700\n",
            "Epoch 807/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 808/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 809/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 810/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 811/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 812/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3940 - val_accuracy: 0.8700\n",
            "Epoch 813/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 814/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 815/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 816/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 817/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 818/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 819/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 820/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 821/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3930 - val_accuracy: 0.8700\n",
            "Epoch 822/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 823/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 824/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3933 - val_accuracy: 0.8700\n",
            "Epoch 825/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3912 - val_accuracy: 0.8700\n",
            "Epoch 826/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 827/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8865 - val_loss: 0.3877 - val_accuracy: 0.8700\n",
            "Epoch 828/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 829/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3868 - val_accuracy: 0.8700\n",
            "Epoch 830/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 831/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 832/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 833/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 834/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 835/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 836/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
            "Epoch 837/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3907 - val_accuracy: 0.8700\n",
            "Epoch 838/1000\n",
            "240/240 [==============================] - 1s 3ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3911 - val_accuracy: 0.8700\n",
            "Epoch 839/1000\n",
            "240/240 [==============================] - 1s 3ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 840/1000\n",
            "240/240 [==============================] - 1s 3ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3921 - val_accuracy: 0.8700\n",
            "Epoch 841/1000\n",
            "240/240 [==============================] - 1s 3ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 842/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3947 - val_accuracy: 0.8700\n",
            "Epoch 843/1000\n",
            "240/240 [==============================] - 1s 3ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 844/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3903 - val_accuracy: 0.8700\n",
            "Epoch 845/1000\n",
            "240/240 [==============================] - 1s 3ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 846/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 847/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3926 - val_accuracy: 0.8700\n",
            "Epoch 848/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 849/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3960 - val_accuracy: 0.8700\n",
            "Epoch 850/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 851/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 852/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3966 - val_accuracy: 0.8700\n",
            "Epoch 853/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 854/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3915 - val_accuracy: 0.8700\n",
            "Epoch 855/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3868 - val_accuracy: 0.8700\n",
            "Epoch 856/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 857/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 858/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3915 - val_accuracy: 0.8700\n",
            "Epoch 859/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 860/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 861/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3922 - val_accuracy: 0.8700\n",
            "Epoch 862/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 863/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3920 - val_accuracy: 0.8700\n",
            "Epoch 864/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
            "Epoch 865/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3872 - val_accuracy: 0.8700\n",
            "Epoch 866/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3910 - val_accuracy: 0.8700\n",
            "Epoch 867/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 868/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 869/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3870 - val_accuracy: 0.8700\n",
            "Epoch 870/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8700\n",
            "Epoch 871/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 872/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 873/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3933 - val_accuracy: 0.8700\n",
            "Epoch 874/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
            "Epoch 875/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3921 - val_accuracy: 0.8700\n",
            "Epoch 876/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 877/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 878/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 879/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 880/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3927 - val_accuracy: 0.8700\n",
            "Epoch 881/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 882/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3936 - val_accuracy: 0.8700\n",
            "Epoch 883/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
            "Epoch 884/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3897 - val_accuracy: 0.8700\n",
            "Epoch 885/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3938 - val_accuracy: 0.8700\n",
            "Epoch 886/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 887/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 888/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 889/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 890/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3928 - val_accuracy: 0.8700\n",
            "Epoch 891/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3862 - val_accuracy: 0.8700\n",
            "Epoch 892/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 893/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3914 - val_accuracy: 0.8700\n",
            "Epoch 894/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 895/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3868 - val_accuracy: 0.8700\n",
            "Epoch 896/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 897/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3918 - val_accuracy: 0.8700\n",
            "Epoch 898/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
            "Epoch 899/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 900/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3948 - val_accuracy: 0.8700\n",
            "Epoch 901/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3922 - val_accuracy: 0.8700\n",
            "Epoch 902/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 903/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 904/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 905/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 906/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3903 - val_accuracy: 0.8700\n",
            "Epoch 907/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 908/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 909/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
            "Epoch 910/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 911/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8700\n",
            "Epoch 912/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3909 - val_accuracy: 0.8700\n",
            "Epoch 913/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3893 - val_accuracy: 0.8700\n",
            "Epoch 914/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 915/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 916/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
            "Epoch 917/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 918/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 919/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 920/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 921/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3899 - val_accuracy: 0.8700\n",
            "Epoch 922/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3889 - val_accuracy: 0.8700\n",
            "Epoch 923/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 924/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3910 - val_accuracy: 0.8700\n",
            "Epoch 925/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 926/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3903 - val_accuracy: 0.8700\n",
            "Epoch 927/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 928/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 929/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8865 - val_loss: 0.3992 - val_accuracy: 0.8700\n",
            "Epoch 930/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8865 - val_loss: 0.3869 - val_accuracy: 0.8700\n",
            "Epoch 931/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 932/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3864 - val_accuracy: 0.8700\n",
            "Epoch 933/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 934/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 935/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3870 - val_accuracy: 0.8700\n",
            "Epoch 936/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3867 - val_accuracy: 0.8700\n",
            "Epoch 937/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3885 - val_accuracy: 0.8700\n",
            "Epoch 938/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8865 - val_loss: 0.3910 - val_accuracy: 0.8700\n",
            "Epoch 939/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3902 - val_accuracy: 0.8700\n",
            "Epoch 940/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 941/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 942/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3930 - val_accuracy: 0.8700\n",
            "Epoch 943/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3942 - val_accuracy: 0.8700\n",
            "Epoch 944/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 945/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3917 - val_accuracy: 0.8700\n",
            "Epoch 946/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 947/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8700\n",
            "Epoch 948/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 949/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 950/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
            "Epoch 951/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3908 - val_accuracy: 0.8700\n",
            "Epoch 952/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3872 - val_accuracy: 0.8700\n",
            "Epoch 953/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 954/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 955/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3915 - val_accuracy: 0.8700\n",
            "Epoch 956/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 957/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3864 - val_accuracy: 0.8700\n",
            "Epoch 958/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
            "Epoch 959/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3905 - val_accuracy: 0.8700\n",
            "Epoch 960/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 961/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3900 - val_accuracy: 0.8700\n",
            "Epoch 962/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8865 - val_loss: 0.3914 - val_accuracy: 0.8700\n",
            "Epoch 963/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3914 - val_accuracy: 0.8700\n",
            "Epoch 964/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 965/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
            "Epoch 966/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 967/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3961 - val_accuracy: 0.8700\n",
            "Epoch 968/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3937 - val_accuracy: 0.8700\n",
            "Epoch 969/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3916 - val_accuracy: 0.8700\n",
            "Epoch 970/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3917 - val_accuracy: 0.8700\n",
            "Epoch 971/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 972/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 973/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 974/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 975/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 976/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3912 - val_accuracy: 0.8700\n",
            "Epoch 977/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8865 - val_loss: 0.3870 - val_accuracy: 0.8700\n",
            "Epoch 978/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8865 - val_loss: 0.3949 - val_accuracy: 0.8700\n",
            "Epoch 979/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8865 - val_loss: 0.3888 - val_accuracy: 0.8700\n",
            "Epoch 980/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 981/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3925 - val_accuracy: 0.8700\n",
            "Epoch 982/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 983/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3917 - val_accuracy: 0.8700\n",
            "Epoch 984/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3883 - val_accuracy: 0.8700\n",
            "Epoch 985/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 986/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 987/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8865 - val_loss: 0.3945 - val_accuracy: 0.8700\n",
            "Epoch 988/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8865 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 989/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 990/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3871 - val_accuracy: 0.8700\n",
            "Epoch 991/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3898 - val_accuracy: 0.8700\n",
            "Epoch 992/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8865 - val_loss: 0.3924 - val_accuracy: 0.8700\n",
            "Epoch 993/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
            "Epoch 994/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3917 - val_accuracy: 0.8700\n",
            "Epoch 995/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8700\n",
            "Epoch 996/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3876 - val_accuracy: 0.8700\n",
            "Epoch 997/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8865 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 998/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8865 - val_loss: 0.3884 - val_accuracy: 0.8700\n",
            "Epoch 999/1000\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8865 - val_loss: 0.3938 - val_accuracy: 0.8700\n",
            "Epoch 1000/1000\n",
            "240/240 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8865 - val_loss: 0.3918 - val_accuracy: 0.8700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4927fdf748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb7BWG4SCI0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "665b905a-f74f-48c8-bb86-03390110364b"
      },
      "source": [
        "print(\"Training Score : \",model.evaluate(X_train,y_train)[1])\n",
        "print(\"Testing Score : \",model.evaluate(X_test,y_test)[1])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "240/240 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8865\n",
            "Training Score :  0.8864526152610779\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8700\n",
            "Testing Score :  0.8700417280197144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVGanM5XDp27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Under fitting is best mananged with RMS prop Optimzer"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt_pTFDELVHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}